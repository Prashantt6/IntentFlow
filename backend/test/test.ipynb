{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78073773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['add a task', 'create a new task', 'put this in my todo list', 'remind me to', 'add something to my tasks', 'schedule a task', 'create a reminder', 'I need to do something', 'make a new todo', 'task garnu xa', 'kaam garnu xa', 'yo kaam add gara', 'samjha malai', 'yo yaad gara', 'yo task rakha', 'yo todo ma haal', 'kaam thap gara', 'reminder set gara', 'yo pani list ma rakha']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    with open('../intents.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "        add_task = data['add_task']\n",
    "        print(add_task)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File doesnt exists\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Not a json file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec193a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de250fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = []\n",
    "for phrase in add_task:\n",
    "    for i in sent_tokenize(phrase):\n",
    "        # print(i)\n",
    "        word.append(i)\n",
    "        # temp = []\n",
    "        # for j in word_tokenize(i):\n",
    "        #     temp.append(j.lower())\n",
    "        # word.append(temp)\n",
    "# for w in word:\n",
    "#     print(w)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbe428",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = gensim.models.Word2Vec(sentences=word, min_count=1,vector_size=10, window=5)\n",
    "print(model1.wv.index_to_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.wv['add task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d1b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"yo task gar\"\n",
    "test= []\n",
    "for j in word_tokenize(input):\n",
    "    test.append(j)\n",
    "\n",
    "test_model = gensim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4fbb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I love machine learning\",\n",
    "    \"Natural language processing is fascinating\",\n",
    "    \"Deep learning is a subset of machine learning\",\n",
    "    \"Word embeddings are key for NLP tasks\",\n",
    "    \"I enjoy exploring AI concepts\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3286eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.utils import simple_preprocess\n",
    "\n",
    "# processed_sentences = [simple_preprocess(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a00811c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 751.06it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') #Downloading model\n",
    "\n",
    "embeddings = model.encode(add_task)    \n",
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a30f2695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match: task garnu xa\n"
     ]
    }
   ],
   "source": [
    "input = 'yo task garnu xa'\n",
    "input_embedding = model.encode([input])\n",
    "\n",
    "similarities = cosine_similarity(input_embedding, embeddings)\n",
    "\n",
    "best_match = similarities.argmax()\n",
    "\n",
    "print(\"Best match:\",add_task[best_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4a4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca07c33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
